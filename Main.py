import pandas as pd
import re
import numpy as np
import os
import keras
import scipy
import matplotlib as plt
from keras.layers import Dense, GlobalAveragePooling2D, Activation, concatenate, Reshape, Input, Conv2D, Concatenate, BatchNormalization, Add
from keras.initializers import VarianceScaling
from keras.applications import ResNet50
#from keras.preprocessing import image
from PIL import Image
from keras.applications.resnet50 import preprocess_input
from keras.preprocessing.image import ImageDataGenerator
from keras.preprocessing.image import img_to_array
from keras.models import Model
from keras.optimizers import Adam
import tensorflow as tf
from tensorflow.python.client import device_lib
from keras.preprocessing.image import load_img
from scipy.spatial.transform import Rotation as R

# print(device_lib.list_local_devices())
def loadImages(numImages):
    images = np.zeros((numImages,256,341,3))
    xyz = np.zeros((numImages,3))
    q = np.zeros((numImages,4))
    # load the image
    for i in range(numImages):
        # Load in image
        mainFilePath = "./7scenes/chess/seq-01/frame"
        imageFileName = "{}-{}.color.png".format(mainFilePath,str(i).zfill(6))
        img = load_img(imageFileName)
        img = img.resize((341,256),Image.ANTIALIAS)
        images[i,:,:,:] = img_to_array(img)

        # Load in pose data
        poseFileName = "{}-{}.pose.txt".format(mainFilePath,str(i).zfill(6))
        file_handle = open(poseFileName, 'r')
        # Read in all the lines of your file into a list of lines
        lines_list = file_handle.readlines()
        # Do a double-nested list comprehension to store as a Homogeneous Transform matrix
        homogeneousTransformList = [[float(val) for val in line.split()] for line in lines_list[0:]]
        homogeneousTransform = np.zeros((4,4))

        for j in range(4):
            homogeneousTransform[j,:] = homogeneousTransformList[j]

        # Extract rotation from homogeneous Transform
        r = R.from_dcm(homogeneousTransform[0:3,0:3])
        q[i,:] = r.as_quat()
        # Extract xyz from homogeneous Transform
        xyz[i,:] = homogeneousTransform[0:3,3]

        file_handle.close()
    return images,xyz,q

# Following 2 functions copied from https://jkjung-avt.github.io/keras-image-cropping/
def random_crop(img, random_crop_size):
    # Note: image_data_format is 'channel_last'
    assert img.shape[2] == 3
    height, width = img.shape[0], img.shape[1]
    dy, dx = random_crop_size
    x = np.random.randint(0, width - dx + 1)
    y = np.random.randint(0, height - dy + 1)
    return img[y:(y+dy), x:(x+dx), :]

# This function has been modified from source to remove references to yield
def crop_generator(batches, crop_length):
    """Take as input a Keras ImageGen (Iterator) and generate random
    crops from the image batches generated by the original iterator.
    """
    batch_crops = np.zeros((batches.shape[0], crop_length, crop_length, 3))
    for i in range(batches.shape[0]):
        batch_crops[i] = random_crop(batches[i], (crop_length, crop_length))
    return batch_crops

def insert_layer_nonseq(model, layer_regex, insert_layer_factory,
                        insert_layer_name=None, position='after', special=False, special_layer=None):

    # Auxiliary dictionary to describe the network graph
    network_dict = {'input_layers_of': {}, 'new_output_tensor_of': {}}

    # Set the input layers of each layer
    for layer in model.layers:
        for node in layer._outbound_nodes:
            layer_name = node.outbound_layer.name
            if layer_name not in network_dict['input_layers_of']:
                network_dict['input_layers_of'].update(
                        {layer_name: [layer.name]})
            else:
                network_dict['input_layers_of'][layer_name].append(layer.name)

    # Set the output tensor of the input layer
    network_dict['new_output_tensor_of'].update(
            {model.layers[0].name: model.input})

    # Iterate over all layers after the input
    for layer in model.layers[1:]:

        # Determine input tensors
        layer_input = [network_dict['new_output_tensor_of'][layer_aux]
                for layer_aux in network_dict['input_layers_of'][layer.name]]
        if len(layer_input) == 1:
            layer_input = layer_input[0]

        # Insert layer if name matches the regular expression
        if re.match(layer_regex, layer.name):
            if position == 'replace':
                x = layer_input
            elif position == 'after':
                x = layer(layer_input)
            elif position == 'before':
                pass
            else:
                raise ValueError('position must be: before, after or replace')

            if (special == False):
                new_layer = insert_layer_factory()
                if insert_layer_name:
                    new_layer.name = insert_layer_name
                else:
                    new_layer.name = layer.name
                x = new_layer(x)
            else:
                new_layer = Concatenate([layer_input, special_layer])
                if insert_layer_name:
                    new_layer.name = insert_layer_name
                else:
                    new_layer.name = layer.name
                x = new_layer
            print('Layer {} inserted after layer {}'.format(new_layer.name,
                                                            layer.name))
            if position == 'before':
                x = layer(x)
        else:
            x = layer(layer_input)

        # Set new output tensor (the original one, or the one of the inserted
        # layer)
        network_dict['new_output_tensor_of'].update({layer.name: x})

    return Model(inputs=model.inputs, outputs=x)

def insert_feedback_loop(model):
    #########################################################################
    ######    Inserting feedback loop    ####################################
    #########################################################################
    activation_40 = model.get_layer('activation_40').output
    input_xyz_prev = Input(shape=(3,), name='input_xyz_prev')
    input_q_prev = Input(shape=(4,), name='input_q_prev')
    xyzq = concatenate([input_xyz_prev, input_q_prev])
    fc4 = Dense(200704, activation='elu', name='fc4')(xyzq)
    fc4Reshaped = Reshape((14, 14, -1))(fc4)
    feedbackLoopInserted = concatenate([activation_40, fc4Reshaped])

    ####################################################################
    #    Replacing Res5 components after feedback loop    ##############
    ####################################################################

    ################################
    # Res5a Main Branch ############
    ################################

    #############
    # Res5a A ###
    #############
    x = Conv2D(filters=512, kernel_size=(1, 1), strides=(2, 2), padding='valid', data_format='channels_last', activation='linear',
               kernel_initializer=VarianceScaling(scale=2.0), name='res5a_branch2a')(feedbackLoopInserted)
    x = BatchNormalization(axis=3,name='bn5a_branch2a')(x)
    x = Activation('elu',name='activation_41')(x)

    #############
    # Res5a B ###
    #############
    x = Conv2D(filters=512, kernel_size=(3, 3), strides=(1, 1), padding='same', data_format='channels_last', activation='linear',
               kernel_initializer=VarianceScaling(scale=2.0), name='res5a_branch2b')(x)
    x = BatchNormalization(axis=3, name='bn5a_branch2b')(x)
    x = Activation('elu', name='activation_42')(x)

    #############
    # Res5a C ###
    #############
    x = Conv2D(filters=2048, kernel_size=(1, 1), strides=(1, 1), padding='valid', data_format='channels_last', activation='linear',
               kernel_initializer=VarianceScaling(scale=2.0), name='res5a_branch2c')(x)
    x = BatchNormalization(axis=3, name='bn5a_branch2c')(x)

    ################################
    # Res5a Skip Branch ############
    ################################
    y = Conv2D(filters=2048, kernel_size=(1, 1), strides=(2, 2), padding='valid', data_format='channels_last', activation='linear',
               kernel_initializer=VarianceScaling(scale=2.0), name='res5a_branch1')(feedbackLoopInserted)
    y = BatchNormalization(axis=3, name='bn5a_branch1')(y)

    ################################
    # Res5b Main Branch ############
    ################################
    x = Add(name='add_14')([x,y])
    y = Activation('elu', name='activation_43')(x)

    #############
    # Res5b A ###
    #############
    x = Conv2D(filters=512, kernel_size=(1, 1), strides=(1, 1), padding='valid', data_format='channels_last',
               activation='linear', kernel_initializer=VarianceScaling(scale=2.0), name='res5b_branch2a')(y)
    x = BatchNormalization(axis=3, name='bn5b_branch2a')(x)
    x = Activation('elu', name='activation_44')(x)

    #############
    # Res5b B ###
    #############
    x = Conv2D(filters=512, kernel_size=(3, 3), strides=(1, 1), padding='same', data_format='channels_last',
               activation='linear', kernel_initializer=VarianceScaling(scale=2.0), name='res5b_branch2b')(x)
    x = BatchNormalization(axis=3, name='bn5b_branch2b')(x)
    x = Activation('elu', name='activation_45')(x)

    #############
    # Res5b C ###
    #############
    x = Conv2D(filters=2048, kernel_size=(1, 1), strides=(1, 1), padding='valid', data_format='channels_last',
               activation='linear', kernel_initializer=VarianceScaling(scale=2.0), name='res5b_branch2c')(x)
    x = BatchNormalization(axis=3, name='bn5b_branch2c')(x)

    ################################
    # Res5c Main Branch ############
    ################################
    x = Add(name='add_15')([x, y])
    y = Activation('elu', name='activation_46')(x)

    #############
    # Res5c A ###
    #############
    x = Conv2D(filters=512, kernel_size=(1, 1), strides=(1, 1), padding='valid', data_format='channels_last',
               activation='linear', kernel_initializer=VarianceScaling(scale=2.0), name='res5c_branch2a')(y)
    x = BatchNormalization(axis=3, name='bn5c_branch2a')(x)
    x = Activation('elu', name='activation_47')(x)

    #############
    # Res5c B ###
    #############
    x = Conv2D(filters=512, kernel_size=(3, 3), strides=(1, 1), padding='same', data_format='channels_last',
               activation='linear', kernel_initializer=VarianceScaling(scale=2.0), name='res5c_branch2b')(x)
    x = BatchNormalization(axis=3, name='bn5c_branch2b')(x)
    x = Activation('elu', name='activation_48')(x)

    #############
    # Res5c C ###
    #############
    x = Conv2D(filters=2048, kernel_size=(1, 1), strides=(1, 1), padding='valid', data_format='channels_last',
               activation='linear', kernel_initializer=VarianceScaling(scale=2.0), name='res5c_branch2c')(x)
    x = BatchNormalization(axis=3, name='bn5c_branch2c')(x)

    ##################
    # End of Res5c ###
    ##################
    x = Add(name='add_16')([x, y])
    x = Activation('elu', name='activation_49')(x)

    return Model(inputs=[model.input,input_xyz_prev, input_q_prev], outputs=x)

x_train, y_xyz_train, y_q_train = loadImages(1000)
print("x_train shape: ",x_train.shape)
print("y_xyz_train shape: ",y_xyz_train.shape)
print("y_q_train shape: ",y_q_train.shape)
base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224,224,3))




# Replace all ReLUs with ELUs
def dropout_layer_factory():
    return Activation('elu')


base_model = insert_layer_nonseq(model=base_model, layer_regex='.*activation.*', insert_layer_factory=dropout_layer_factory, position='replace')

base_model = insert_feedback_loop(base_model)

x = base_model.output
x = GlobalAveragePooling2D()(x)  # **** Assuming 2D, with no arguments required
x = Dense(1024, activation='elu', name='fc1')(x)  # **** Assuming relu
xyz = Dense(3, activation='softmax', name='xyz')(x)  # **** Assuming softmax is the correct activation here
q = Dense(4, activation='softmax', name='q')(x)  # **** Assuming softmax (rho/theta/phi) and quaternians

#global_pose_network = Model(inputs=base_model.input, outputs=[xyz, q])
global_pose_network = Model(inputs=base_model.inputs, outputs=[xyz, q])

global_pose_network.compile(optimizer='Adam',loss='mean_squared_error')
global_pose_network.summary()

train_datagen = ImageDataGenerator(featurewise_center=True)
# compute quantities required for featurewise normalization
# (std, mean, and principal components if ZCA whitening is applied)
train_datagen.fit(x_train)
train_crops = crop_generator(x_train, 224)

#global_pose_network.fit(x=train_crops, y={'xyz' : y_xyz_train, 'q': y_q_train}, batch_size=32, verbose=1, shuffle=False, epochs=1)

#layer = base_model.get_layer('bn5c_branch2c').get_config()
#print(layer)

print("Finished Successfully")